import tensorflow as tf
from tensorflow.keras import layers, models
import numpy as np
import os, random

#CẤU HÌNH
IMG_SIZE = (112, 112)
BATCH_SIZE = 16
EPOCHS = 25
DATA_DIR = "data_aligned"
MARGIN = 0.5


# Mô hình embedding (FaceNet mini)
def build_facenet_base():
    model = models.Sequential([
        layers.Input(shape=(*IMG_SIZE, 3)),
        layers.Conv2D(32, (3,3), activation='relu', padding='same'),
        layers.MaxPooling2D(),
        layers.Conv2D(64, (3,3), activation='relu', padding='same'),
        layers.MaxPooling2D(),
        layers.Conv2D(128, (3,3), activation='relu', padding='same'),
        layers.GlobalAveragePooling2D(),
        layers.Dense(512, activation=None),  # không có activation để giữ vector gốc
        layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1))  # chuẩn hóa L2
    ])
    return model

base_model = build_facenet_base()

#Cosine embedding loss (chuẩn hóa, ổn định hơn)
def cosine_embedding_loss(y_true, y_pred, margin=MARGIN):
    emb_dim = tf.shape(y_pred)[1] // 2
    emb1 = y_pred[:, :emb_dim]
    emb2 = y_pred[:, emb_dim:]

    emb1 = tf.math.l2_normalize(emb1, axis=1)
    emb2 = tf.math.l2_normalize(emb2, axis=1)
    cosine_sim = tf.reduce_sum(emb1 * emb2, axis=1)
    y_true = tf.squeeze(y_true)

    pos_loss = 1.0 - cosine_sim
    neg_loss = tf.maximum(0.0, cosine_sim - margin)
    loss = tf.where(y_true > 0, pos_loss, neg_loss)
    return tf.reduce_mean(loss)

#Sinh cặp ảnh (positive & negative)
def load_pair_batch(data_dir, batch_size=BATCH_SIZE):
    chu_nha_dir = os.path.join(data_dir, "chu_nha")
    nguoi_la_dir = os.path.join(data_dir, "nguoi_la")

    chu_nha = [os.path.join(chu_nha_dir, f) for f in os.listdir(chu_nha_dir)
               if f.lower().endswith(('.jpg','.png','.jpeg'))]
    nguoi_la = [os.path.join(nguoi_la_dir, f) for f in os.listdir(nguoi_la_dir)
                if f.lower().endswith(('.jpg','.png','.jpeg'))]

    while True:
        imgs1, imgs2, labels = [], [], []
        for _ in range(batch_size):
            if random.random() < 0.5 and len(chu_nha) >= 2:
                # Positive pair
                a, b = random.sample(chu_nha, 2)
                label = 1.0
            else:
                # Negative pair
                a = random.choice(chu_nha)
                b = random.choice(nguoi_la)
                label = -1.0

            img1 = tf.keras.preprocessing.image.load_img(a, target_size=IMG_SIZE)
            img2 = tf.keras.preprocessing.image.load_img(b, target_size=IMG_SIZE)
            img1 = tf.keras.preprocessing.image.img_to_array(img1) / 255.0
            img2 = tf.keras.preprocessing.image.img_to_array(img2) / 255.0

            imgs1.append(img1)
            imgs2.append(img2)
            labels.append(label)
        yield [np.array(imgs1), np.array(imgs2)], np.array(labels).reshape(-1,1)

#Mô hình Siamese network
input1 = layers.Input(shape=(*IMG_SIZE, 3))
input2 = layers.Input(shape=(*IMG_SIZE, 3))
emb1 = base_model(input1)
emb2 = base_model(input2)
merged = layers.Concatenate(axis=1)([emb1, emb2])
model = models.Model(inputs=[input1, input2], outputs=merged)

#Compile & train
model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=cosine_embedding_loss)
train_gen = load_pair_batch(DATA_DIR, batch_size=BATCH_SIZE)

print("[INFO] Training model...")
model.fit(train_gen, steps_per_epoch=30, epochs=EPOCHS, verbose=1)

# Lưu base model & TFLite (float16 để tăng tốc)
base_model.save("facenet_cosine_base.h5")
converter = tf.lite.TFLiteConverter.from_keras_model(base_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_types = [tf.float16]   # chạy nhanh hơn ~2x
tflite_model = converter.convert()
with open("facenet_cosine_base.tflite", "wb") as f:
    f.write(tflite_model)

print("Saved facenet_cosine_base.tflite (112x112 RGB normalized [0,1])")
